What is Kubernetes? Its an open-source system for automating deployment, scaling and management of containerized applications. also know as k8s, This is actually designed for scale and run anywhere.

Why kubernetes? 
- Few containers are fine but what about scale
- How do monitor those containers?
- What about running pods on multiple nodes?
- What about flexibility?
- autoscaling?
- Scheduling?
- Self healing capabilities?

All above things we can do through kubernetes instead of doing manually.

the primary reason for using kubernets is to orchestrate containers in a containerized application. containerization allows users to package applications into a single immutable and isolated container with all the dependencies that can be deployed virtually anywhere.

Managing a single or handful of containers won't be that much of a hassle. Furthermore, depending on the functionality or use case , users can even deploy containers a functions to leverage FaaS services such as Azure Functions ( Function App container)

However , the number of containers can balloon up to hundreds and even thousands of containers in most production environments. This will lead to a management overhead that would be hard-pressed to handle by even a large team. Yet, Kubernetes manage most management tasks of containers as well as scaling, availabilty, Storage, security and networking within the kubernetes cluster by using kubernetes to manage all these containers.

Kubernetes is most effective when managing containers at scale, setup the k8 cluster and plug it into a devops pipeline, and users will get a streamlined delivery pipeline to support the complete application lifecycle.

What is the main components of kubernetes architecture?
kubernetes has two main components:
>>> The Control Plane: 
- manage the kubernetes cluster
- This is main nerve centre of each cluster
- This is responsible for ensuring that the kubernetes cluster attains a desired state, defined by the user in a declarative manner

>>> Worker nodes     : Can be virtual or physical machine, a node hosts pods, which run one or more cotainers


Here are the main componnent of the control Plane:
1. Kube -apiserver: 
- provides an API that serves as the front end of a kubernetes control Plane
- responsible for handling external and internal requests
- Determing wheather is request is valid and then processing internal

2. Kube-scheduler: 
- Responsible for scheduling pods on specific nodes according to automated workflows and user defined conditions
, which can nclude resource requests, concerns like affinity and taint or tolerations, priority, persistant volumes and more

3. Kube-controller manager: 
- this is a control lopp that monitors and regulates the state of kubernetes cluster
- this receives information about the current state of the cluster and objects within internal
- This control manager is responsible for several controllers that handle various automated activities at the cluster or pod level, including replication controller, namespace controller , service accounts controller, deployment, statefulset ad daemonset

4. etcd : 
- A key value database that contains data about your cluster state and configuration.
ETCD is fault tolerent and distributed.

5. Cloud-controller-manager:
- This is specific to the cloud provider, not required for on-premises kubernetes environments
- This component can embed cloud specific control logic, for example, it can access the clound provider load balancer service, enable to connect a kubernetes cluster with the API of a cloud provider

Here are the main component of worker nodes:
1. Nodes:
- This is physical or VM that can run pods as part of kubernetes cluster.
- A cluster can scale up 5000 nodes, to scale cluster capacity, you can add more nodes

2. pods
- This is considered the samllest unit in kubernetes
- Each pod consists of one or more tightly coupled containers. and configurations how containers should run
- Pod contains at least one container

3. Container Runtime Engine:
Each node comes with a container runtime engine, which is responsible for running containers. Docker is a popular container runtime engine, but Kubernetes supports other runtimes that are compliant with Open Container Initiative, including CRI-O and rkt.

4. Kubelet:
Each node contains a kubelet, which is a small application that can communicate with the Kubernetes control plane. The kubelet is responsible for ensuring that containers specified in pod configuration are running on a specific node, and manages their lifecycle.. It executes the actions commanded by your control plane.

5. Kube-proxy:
All compute nodes contain kube-proxy, a network proxy that facilitates Kubernetes networking services. It handles all network communications outside and inside the cluster, forwarding traffic or replying on the packet filtering layer of the operating system.

6. Container Networking:
Container networking enables containers to communicate with hosts or other containers. It is often achieved by using the container networking interface (CNI), which is a joint initiative by Kubernetes, Apache Mesos, Cloud Foundry, Red Hat OpenShift, and others.

 7. Kubernetes Persistant Storage:
 Containers are designed as immutable entities. Once a container is shut, all the data created during the container’s lifetime is lost. While this stateless characteristic is ideal for some applications, many use cases require preserving and sharing information.

You can set up Kubernetes persistent storage to allow applications to consume and request storage resources. You can do this by using volumes, which serve as basic components of a Kubernetes storage architecture.

PersistentVolumes (PVs) are storage resources designed to enable durable storage for containerized applications in Kubernetes. Each PV is a persistent storage component within the Kubernetes architecture. 

PV resources belong to the cluster but exist independently of pods. To ensure statefulness, each disk and data represented by PVs continue existing even as changes occur to the cluster, regardless of deletion and recreation of pods.

There are two ways to create PVs—manually and dynamically. Dynamic creation of PVs involves the use of PersistentVolumeClaims (PVCs) that define the details of a resource request, letting Kubernetes manage the lifecycle of PVs


Kubernetes Helm:
With Kubernetes, Helm serves as a package manager, working similarly to npm in Node.js and yum in Linux. Helm deploys charts as complete and packaged Kubernetes applications, which include pre-configured versioned application resources. It is possible to deploy different chart versions by using different configuration sets.

Helm plays a key role within the Kubernetes architecture. It can, for example, significantly improve productivity and deployment, and reduce the complexity of Kubernetes applications. You can leverage Helm charts to easily manage cloud-native applications and microservices.
